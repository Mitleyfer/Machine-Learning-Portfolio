{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Машинное обучение 1: линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 1. \n",
    "##### Научимся строить модель линейной регрессии для больших объемов данных и оценивать ее качество"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделите набор данных на обучающие/проверочные в пропорции 80/20.\n",
    "\n",
    "Загрузите данные и очистите значения (нулями и средними). Постройте модель линейной регрессии для каждого часа в отдельности, используя температуру воздуха (air_temperature), влажность (dew_temperature), атмосферное давление (sea_level_pressure), скорость ветра (wind_speed) и облачность (cloud_coverage).\n",
    "\n",
    "Рассчитайте качество построенной модели по проверочным данным. Используйте данные:\n",
    "\n",
    "http://video.ittensive.com/machine-learning/ashrae/building_metadata.csv.gz\n",
    "\n",
    "http://video.ittensive.com/machine-learning/ashrae/weather_train.csv.gz\n",
    "\n",
    "http://video.ittensive.com/machine-learning/ashrae/train.0.0.csv.gz\n",
    "\n",
    "Какое получилось качество модели линейной регрессии по часам с точностью до десятых?\n",
    "\n",
    "_______________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем данные в датафреймы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   site_id  building_id primary_use  square_feet  year_built  floor_count\n",
      "0        0            0   Education         7432      2008.0          NaN\n",
      "1        0            1   Education         2720      2004.0          NaN\n",
      "2        0            2   Education         5376      1991.0          NaN\n",
      "3        0            3   Education        23685      2002.0          NaN\n",
      "4        0            4   Education       116607      1975.0          NaN\n"
     ]
    }
   ],
   "source": [
    "df_buildings = pd.read_csv('http://video.ittensive.com/machine-learning/ashrae/building_metadata.csv.gz')\n",
    "df_weather = pd.read_csv('http://video.ittensive.com/machine-learning/ashrae/weather_train.csv.gz').set_index(['timestamp', 'site_id'])\n",
    "df_train = pd.read_csv('http://video.ittensive.com/machine-learning/ashrae/train.0.0.csv.gz')\n",
    "\n",
    "print(df_buildings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             air_temperature  cloud_coverage  dew_temperature  \\\n",
      "timestamp           site_id                                                     \n",
      "2016-01-01 00:00:00 0                   25.0             6.0             20.0   \n",
      "2016-01-01 01:00:00 0                   24.4             NaN             21.1   \n",
      "2016-01-01 02:00:00 0                   22.8             2.0             21.1   \n",
      "2016-01-01 03:00:00 0                   21.1             2.0             20.6   \n",
      "2016-01-01 04:00:00 0                   20.0             2.0             20.0   \n",
      "\n",
      "                             precip_depth_1_hr  sea_level_pressure  \\\n",
      "timestamp           site_id                                          \n",
      "2016-01-01 00:00:00 0                      NaN              1019.7   \n",
      "2016-01-01 01:00:00 0                     -1.0              1020.2   \n",
      "2016-01-01 02:00:00 0                      0.0              1020.2   \n",
      "2016-01-01 03:00:00 0                      0.0              1020.1   \n",
      "2016-01-01 04:00:00 0                     -1.0              1020.0   \n",
      "\n",
      "                             wind_direction  wind_speed  \n",
      "timestamp           site_id                              \n",
      "2016-01-01 00:00:00 0                   0.0         0.0  \n",
      "2016-01-01 01:00:00 0                  70.0         1.5  \n",
      "2016-01-01 02:00:00 0                   0.0         0.0  \n",
      "2016-01-01 03:00:00 0                   0.0         0.0  \n",
      "2016-01-01 04:00:00 0                 250.0         2.6  \n"
     ]
    }
   ],
   "source": [
    "print(df_weather.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   building_id  meter            timestamp  meter_reading\n",
      "0            0      0  2016-01-01 00:00:00            0.0\n",
      "1            0      0  2016-01-01 01:00:00            0.0\n",
      "2            0      0  2016-01-01 02:00:00            0.0\n",
      "3            0      0  2016-01-01 03:00:00            0.0\n",
      "4            0      0  2016-01-01 04:00:00            0.0\n"
     ]
    }
   ],
   "source": [
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединяем датафреймы в один по общим колонкам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>site_id</th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>meter_reading</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>year_built</th>\n",
       "      <th>floor_count</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>cloud_coverage</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>precip_depth_1_hr</th>\n",
       "      <th>sea_level_pressure</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Education</td>\n",
       "      <td>7432</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1019.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01 01:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Education</td>\n",
       "      <td>7432</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1020.2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01 02:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Education</td>\n",
       "      <td>7432</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1020.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01 03:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Education</td>\n",
       "      <td>7432</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1020.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01 04:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Education</td>\n",
       "      <td>7432</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp  site_id  building_id  meter  meter_reading  \\\n",
       "0  2016-01-01 00:00:00        0            0      0            0.0   \n",
       "1  2016-01-01 01:00:00        0            0      0            0.0   \n",
       "2  2016-01-01 02:00:00        0            0      0            0.0   \n",
       "3  2016-01-01 03:00:00        0            0      0            0.0   \n",
       "4  2016-01-01 04:00:00        0            0      0            0.0   \n",
       "\n",
       "  primary_use  square_feet  year_built  floor_count  air_temperature  \\\n",
       "0   Education         7432      2008.0          NaN             25.0   \n",
       "1   Education         7432      2008.0          NaN             24.4   \n",
       "2   Education         7432      2008.0          NaN             22.8   \n",
       "3   Education         7432      2008.0          NaN             21.1   \n",
       "4   Education         7432      2008.0          NaN             20.0   \n",
       "\n",
       "   cloud_coverage  dew_temperature  precip_depth_1_hr  sea_level_pressure  \\\n",
       "0             6.0             20.0                NaN              1019.7   \n",
       "1             NaN             21.1               -1.0              1020.2   \n",
       "2             2.0             21.1                0.0              1020.2   \n",
       "3             2.0             20.6                0.0              1020.1   \n",
       "4             2.0             20.0               -1.0              1020.0   \n",
       "\n",
       "   wind_direction  wind_speed  \n",
       "0             0.0         0.0  \n",
       "1            70.0         1.5  \n",
       "2             0.0         0.0  \n",
       "3             0.0         0.0  \n",
       "4           250.0         2.6  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_train.merge(df_buildings, how = 'left', on = 'building_id')\n",
    "df.set_index(['timestamp', 'site_id'], inplace = True)\n",
    "df = df.merge(df_weather, left_index = True, right_index = True, how = 'left')\n",
    "df.reset_index(inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем наличие пропусков и типы данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8784 entries, 0 to 8783\n",
      "Data columns (total 16 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   timestamp           8784 non-null   object \n",
      " 1   site_id             8784 non-null   int64  \n",
      " 2   building_id         8784 non-null   int64  \n",
      " 3   meter               8784 non-null   int64  \n",
      " 4   meter_reading       8784 non-null   float64\n",
      " 5   primary_use         8784 non-null   object \n",
      " 6   square_feet         8784 non-null   int64  \n",
      " 7   year_built          8784 non-null   float64\n",
      " 8   floor_count         0 non-null      float64\n",
      " 9   air_temperature     8781 non-null   float64\n",
      " 10  cloud_coverage      4954 non-null   float64\n",
      " 11  dew_temperature     8781 non-null   float64\n",
      " 12  precip_depth_1_hr   8783 non-null   float64\n",
      " 13  sea_level_pressure  8699 non-null   float64\n",
      " 14  wind_direction      8534 non-null   float64\n",
      " 15  wind_speed          8784 non-null   float64\n",
      "dtypes: float64(10), int64(4), object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приводим дату к типу datetime и выделяем данные по часам в отдельную колонку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>site_id</th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>meter_reading</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>year_built</th>\n",
       "      <th>floor_count</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>cloud_coverage</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>precip_depth_1_hr</th>\n",
       "      <th>sea_level_pressure</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Education</td>\n",
       "      <td>7432</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1019.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01 01:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Education</td>\n",
       "      <td>7432</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1020.2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01 02:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Education</td>\n",
       "      <td>7432</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1020.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01 03:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Education</td>\n",
       "      <td>7432</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1020.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01 04:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Education</td>\n",
       "      <td>7432</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp  site_id  building_id  meter  meter_reading primary_use  \\\n",
       "0 2016-01-01 00:00:00        0            0      0            0.0   Education   \n",
       "1 2016-01-01 01:00:00        0            0      0            0.0   Education   \n",
       "2 2016-01-01 02:00:00        0            0      0            0.0   Education   \n",
       "3 2016-01-01 03:00:00        0            0      0            0.0   Education   \n",
       "4 2016-01-01 04:00:00        0            0      0            0.0   Education   \n",
       "\n",
       "   square_feet  year_built  floor_count  air_temperature  cloud_coverage  \\\n",
       "0         7432      2008.0          NaN             25.0             6.0   \n",
       "1         7432      2008.0          NaN             24.4             NaN   \n",
       "2         7432      2008.0          NaN             22.8             2.0   \n",
       "3         7432      2008.0          NaN             21.1             2.0   \n",
       "4         7432      2008.0          NaN             20.0             2.0   \n",
       "\n",
       "   dew_temperature  precip_depth_1_hr  sea_level_pressure  wind_direction  \\\n",
       "0             20.0                NaN              1019.7             0.0   \n",
       "1             21.1               -1.0              1020.2            70.0   \n",
       "2             21.1                0.0              1020.2             0.0   \n",
       "3             20.6                0.0              1020.1             0.0   \n",
       "4             20.0               -1.0              1020.0           250.0   \n",
       "\n",
       "   wind_speed  hours  \n",
       "0         0.0      0  \n",
       "1         1.5      1  \n",
       "2         0.0      2  \n",
       "3         0.0      3  \n",
       "4         2.6      4  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df['hours'] = df['timestamp'].apply(lambda x: x.hour)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполняем пропуски данных средними значениями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8784 entries, 0 to 8783\n",
      "Data columns (total 17 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   timestamp           8784 non-null   datetime64[ns]\n",
      " 1   site_id             8784 non-null   int64         \n",
      " 2   building_id         8784 non-null   int64         \n",
      " 3   meter               8784 non-null   int64         \n",
      " 4   meter_reading       8784 non-null   float64       \n",
      " 5   primary_use         8784 non-null   object        \n",
      " 6   square_feet         8784 non-null   int64         \n",
      " 7   year_built          8784 non-null   float64       \n",
      " 8   floor_count         0 non-null      float64       \n",
      " 9   air_temperature     8784 non-null   float64       \n",
      " 10  cloud_coverage      8784 non-null   float64       \n",
      " 11  dew_temperature     8784 non-null   float64       \n",
      " 12  precip_depth_1_hr   8784 non-null   float64       \n",
      " 13  sea_level_pressure  8784 non-null   float64       \n",
      " 14  wind_direction      8784 non-null   float64       \n",
      " 15  wind_speed          8784 non-null   float64       \n",
      " 16  hours               8784 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float64(10), int64(5), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "means = []\n",
    "columns = ['air_temperature', 'cloud_coverage', 'dew_temperature', 'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction']\n",
    "for col in columns:\n",
    "    means.append(df[col][df[col].notnull()].mean())\n",
    "    df[col].fillna('no_value', inplace = True)\n",
    "for m, col in zip(means, columns):\n",
    "    df[col] = df[col].apply(lambda x: m if x == 'no_value' else x)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модели линейной регрессии по часам. Сохраняем коэффициенты получившихся моделей в список."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[['hours', 'air_temperature', 'dew_temperature', 'sea_level_pressure', 'wind_speed', 'cloud_coverage', 'meter_reading']]\n",
    "coeffs = []\n",
    "errors = []\n",
    "for hour in data.hours.unique():\n",
    "    temp_data = data[data.hours == hour]\n",
    "    temp_data = temp_data[temp_data.meter_reading > 0]\n",
    "    X = temp_data[['air_temperature', 'dew_temperature', 'sea_level_pressure', 'wind_speed', 'cloud_coverage']]\n",
    "    y = temp_data['meter_reading']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    errors.append(mean_squared_error(y_test, preds))\n",
    "    coeffs.append(model.coef_)\n",
    "    coeffs[hour] = np.append(coeffs[hour], model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделяем общий датафрейм на тренировочный и проверочный."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hours</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>sea_level_pressure</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>cloud_coverage</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3663</th>\n",
       "      <td>15</td>\n",
       "      <td>27.8</td>\n",
       "      <td>21.1</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>253.9120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5103</th>\n",
       "      <td>15</td>\n",
       "      <td>31.1</td>\n",
       "      <td>22.8</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>292.8180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>1</td>\n",
       "      <td>19.4</td>\n",
       "      <td>11.7</td>\n",
       "      <td>1018.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>161.7670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8244</th>\n",
       "      <td>12</td>\n",
       "      <td>10.6</td>\n",
       "      <td>6.7</td>\n",
       "      <td>1025.1</td>\n",
       "      <td>7.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>95.5584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4446</th>\n",
       "      <td>6</td>\n",
       "      <td>26.1</td>\n",
       "      <td>23.9</td>\n",
       "      <td>1019.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>252.5470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      hours  air_temperature  dew_temperature  sea_level_pressure  wind_speed  \\\n",
       "3663     15             27.8             21.1              1017.0         1.5   \n",
       "5103     15             31.1             22.8              1019.0         1.5   \n",
       "7609      1             19.4             11.7              1018.9         2.1   \n",
       "8244     12             10.6              6.7              1025.1         7.7   \n",
       "4446      6             26.1             23.9              1019.9         1.5   \n",
       "\n",
       "      cloud_coverage  meter_reading  \n",
       "3663             2.0       253.9120  \n",
       "5103             2.0       292.8180  \n",
       "7609             4.0       161.7670  \n",
       "8244             8.0        95.5584  \n",
       "4446             2.0       252.5470  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[data['meter_reading'] > 0]\n",
    "data_train, data_test = train_test_split(data, test_size = 0.2, random_state = 42)\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.21654766e+00,  2.24701873e+00, -6.98547268e-01, -3.31444424e+00,\n",
       "       -1.46366053e+00,  7.93856523e+02])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычисляем качество почасовой модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество почасовой линейной регрессии, 5 параметров: 0.2\n"
     ]
    }
   ],
   "source": [
    "def calculate_model(x):\n",
    "    model = coeffs[int(x.hours)]\n",
    "    meter_reading_log = np.log(x.meter_reading + 1)\n",
    "    meter_reading_lr = np.log(1 + x.air_temperature * model[0] + \n",
    "        x.dew_temperature * model[1] + x.sea_level_pressure * model[2] +\n",
    "        x.wind_speed * model[3] + x.cloud_coverage * model[4] + model[5])\n",
    "    x['meter_reading_lr_q'] = (meter_reading_log - meter_reading_lr)**2\n",
    "    return x\n",
    "\n",
    "data_test = data_test.apply(calculate_model, axis=1, result_type='expand')\n",
    "data_test_lr_rmsle = np.sqrt(data_test['meter_reading_lr_q'].sum() / len(data_test))\n",
    "print (f'Качество почасовой линейной регрессии, 5 параметров: {round(data_test_lr_rmsle, 1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 2\n",
    "##### Научимся разделять данные на отдельные части, заполнять пропуски в данных и оптимизировать потребление памяти"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получите данные по энергопотреблению первых 20 зданий (building_id от 0 до 19).\n",
    "\n",
    "Заполните отсутствующие значения по погоде интерполяционными данными.\n",
    "\n",
    "Разделите данные на обучающие/проверочные в пропорции 80/20.\n",
    "\n",
    "Постройте и найдите общее качество модели линейной регрессии, построенной по часам для каждого из первых 20 зданий по следующим параметрам: air_temperature, dew_temperature, cloud_coverage, wind_speed, precip_depth_1_hr, sea_level_pressure, is_holiday.\n",
    "\n",
    "Всего требуется построить 480 моделей линейной регрессии, вычислить по ним проверочные значения энергопотребления и получить итоговую оценку качества такой модели.\n",
    "\n",
    "Для расчета последнего параметра (is_holiday) используйте график публичных выходных в США: USFederalHolidayCalendar\n",
    "\n",
    "Исходные данные:\n",
    "\n",
    "https://video.ittensive.com/machine-learning/ashrae/building_metadata.csv.gz\n",
    "\n",
    "https://video.ittensive.com/machine-learning/ashrae/weather_train.csv.gz\n",
    "\n",
    "https://video.ittensive.com/machine-learning/ashrae/train.0.csv.gz\n",
    "\n",
    "Чему равна метрика качества полученной модели с точностью до десятых?\n",
    "\n",
    "_______________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем данные в датафреймы и фильтруем по первым 20 зданиям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_buildings = pd.read_csv('http://video.ittensive.com/machine-learning/ashrae/building_metadata.csv.gz')\n",
    "df_weather = pd.read_csv('http://video.ittensive.com/machine-learning/ashrae/weather_train.csv.gz').set_index(['timestamp', 'site_id'])\n",
    "df_energy = pd.read_csv('http://video.ittensive.com/machine-learning/ashrae/train.0.csv.gz')\n",
    "df_energy = df_energy[df_energy['building_id'].isin(list(range(0, 20)))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соединяем датафреймы по индексам. Приводим дату к типу datetime, затем создаём колонку с часами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter_reading</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>year_built</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>cloud_coverage</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>precip_depth_1_hr</th>\n",
       "      <th>sea_level_pressure</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Education</td>\n",
       "      <td>7432</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1019.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Education</td>\n",
       "      <td>2720</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1019.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Education</td>\n",
       "      <td>5376</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1019.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Education</td>\n",
       "      <td>23685</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1019.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Education</td>\n",
       "      <td>116607</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1019.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  building_id  meter_reading primary_use  square_feet  year_built  \\\n",
       "0 2016-01-01            0            0.0   Education         7432      2008.0   \n",
       "1 2016-01-01            1            0.0   Education         2720      2004.0   \n",
       "2 2016-01-01            2            0.0   Education         5376      1991.0   \n",
       "3 2016-01-01            3            0.0   Education        23685      2002.0   \n",
       "4 2016-01-01            4            0.0   Education       116607      1975.0   \n",
       "\n",
       "   air_temperature  cloud_coverage  dew_temperature  precip_depth_1_hr  \\\n",
       "0             25.0             6.0             20.0                NaN   \n",
       "1             25.0             6.0             20.0                NaN   \n",
       "2             25.0             6.0             20.0                NaN   \n",
       "3             25.0             6.0             20.0                NaN   \n",
       "4             25.0             6.0             20.0                NaN   \n",
       "\n",
       "   sea_level_pressure  wind_direction  wind_speed  hours  \n",
       "0              1019.7             0.0         0.0      0  \n",
       "1              1019.7             0.0         0.0      0  \n",
       "2              1019.7             0.0         0.0      0  \n",
       "3              1019.7             0.0         0.0      0  \n",
       "4              1019.7             0.0         0.0      0  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_energy.merge(df_buildings, how = 'left', on = 'building_id')\n",
    "df.set_index(['timestamp', 'site_id'], inplace = True)\n",
    "df = df.merge(df_weather, left_index = True, right_index = True, how = 'left')\n",
    "df.reset_index(inplace = True)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df['hours'] = df['timestamp'].apply(lambda x: x.hour)\n",
    "df = df.drop(columns=[\"meter\", \"site_id\", \"floor_count\"], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 175680 entries, 0 to 175679\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count   Dtype         \n",
      "---  ------              --------------   -----         \n",
      " 0   timestamp           175680 non-null  datetime64[ns]\n",
      " 1   building_id         175680 non-null  int64         \n",
      " 2   meter_reading       175680 non-null  float64       \n",
      " 3   primary_use         175680 non-null  object        \n",
      " 4   square_feet         175680 non-null  int64         \n",
      " 5   year_built          175680 non-null  float64       \n",
      " 6   air_temperature     175620 non-null  float64       \n",
      " 7   cloud_coverage      99080 non-null   float64       \n",
      " 8   dew_temperature     175620 non-null  float64       \n",
      " 9   precip_depth_1_hr   175660 non-null  float64       \n",
      " 10  sea_level_pressure  173980 non-null  float64       \n",
      " 11  wind_direction      170680 non-null  float64       \n",
      " 12  wind_speed          175680 non-null  float64       \n",
      " 13  hours               175680 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(9), int64(3), object(1)\n",
      "memory usage: 18.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция уменьщения потребления памяти. Итерирует по колонкам, проверяет их тип и, если возможно, приводит их к типу, потребляющему меньше памяти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage (df):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if str(col_type)[:5] == 'float':\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if c_min > np.finfo('f2').min and c_max < np.finfo('f2').max:\n",
    "                df[col] = df[col].astype(np.float16)\n",
    "            elif c_min > np.finfo('f4').min and c_max < np.finfo('f4').max:\n",
    "                df[col] = df[col].astype(np.float32)\n",
    "            else:\n",
    "                df[col] = df[col].astype(np.float64)\n",
    "        elif str(col_type)[:3] == 'int':\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if c_min > np.iinfo('i1').min and c_max < np.iinfo('i1').max:\n",
    "                df[col] = df[col].astype(np.int8)\n",
    "            elif c_min > np.iinfo('i2').min and c_max < np.iinfo('i2').max:\n",
    "                df[col] = df[col].astype(np.int16)\n",
    "            elif c_min > np.iinfo('i4').min and c_max < np.iinfo('i4').max:\n",
    "                df[col] = df[col].astype(np.int32)\n",
    "            elif c_min > np.iinfo('i8').min and c_max < np.iinfo('i8').max:\n",
    "                df[col] = df[col].astype(np.int64)\n",
    "        elif col == 'timestamp':\n",
    "            df[col] = pd.to_datetime(df[col])\n",
    "        elif str(col_type)[:8] != 'datetime':\n",
    "            df[col] = df[col].astype('category')\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(f'Потребление памяти меньше на {round(start_mem - end_mem, 2)} Мб (минус {round(100 * (start_mem - end_mem) / start_mem, 1)} %)')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Потребление памяти меньше на 13.24 Мб (минус 70.5 %\n"
     ]
    }
   ],
   "source": [
    "df = reduce_mem_usage(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполняем пропуски интерполяцией данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "air_temperature Inf+NaN: 0\n",
      "dew_temperature Inf+NaN: 0\n",
      "cloud_coverage Inf+NaN: 0\n",
      "wind_speed Inf+NaN: 0\n",
      "precip_depth_1_hr Inf+NaN: 0\n",
      "sea_level_pressure Inf+NaN: 0\n"
     ]
    }
   ],
   "source": [
    "df['precip_depth_1_hr'] = df['precip_depth_1_hr'].apply(lambda x: x if x > 0 else 0)\n",
    "interpolate_columns = ['air_temperature', 'dew_temperature', 'cloud_coverage', \n",
    "                       'wind_speed', 'precip_depth_1_hr', 'sea_level_pressure']\n",
    "for col in interpolate_columns:\n",
    "    df[col] = df[col].interpolate(limit_direction='both', kind='cubic')\n",
    "    \n",
    "pd.set_option('use_inf_as_na', True)\n",
    "for col in interpolate_columns:\n",
    "    print(col, \"Inf+NaN:\", df[col].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём колонку поясняющую выходной день или нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_range = pd.date_range(start = '2015-12-31', end = '2017-01-01')\n",
    "us_holidays = calendar().holidays(start = dates_range.min(), end = dates_range.max())\n",
    "df['is_holiday'] = (df['timestamp'].isin(us_holidays)).astype('int8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фильтруем данные по показаниям счётчика, они должны быть больше нуля. Делим данные на тестовые и тренировочные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['building_id', 'hours', 'air_temperature', 'dew_temperature', 'cloud_coverage', 'wind_speed',\n",
    "        'precip_depth_1_hr', 'sea_level_pressure', 'is_holiday', 'meter_reading']][df.meter_reading > 0]\n",
    "df_train, df_test = train_test_split(df, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итерируем по индексу зданий и часам. Для каждого здания создаём почасовую модель потребления электричества. Заносим полученные коэффициенты в список."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "coeffs = []\n",
    "for build_id in sorted(df['building_id'].unique()):\n",
    "    for hour in sorted(df.hours.unique()):\n",
    "        X = df_train[df_train['building_id'] == build_id].drop(columns = ['building_id', 'meter_reading'])\n",
    "        X = X[X['hours'] == hour].drop(columns = 'hours')\n",
    "        y = df_train[df_train['building_id'] == build_id]\n",
    "        y = y[y['hours'] == hour]['meter_reading']\n",
    "        model = LinearRegression()\n",
    "        model.fit(X, y)\n",
    "        coeffs.append(model.coef_)\n",
    "        coeffs[hour] = np.append(coeffs[hour], model.intercept_)\n",
    "    models.append(coeffs)\n",
    "    coeffs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем качество модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\AI\\lib\\site-packages\\ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in log\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество модели линейной регрессии: 0.246095\n"
     ]
    }
   ],
   "source": [
    "def calculate_model(x):\n",
    "    model = models[int(x.building_id)][int(x.hours)]\n",
    "    meter_reading_log = np.log(x.meter_reading + 1)\n",
    "    meter_reading_lr = np.log(1 + x.air_temperature * model[0] + \n",
    "        x.dew_temperature * model[1] + x.cloud_coverage * model[2] +\n",
    "        x.wind_speed * model[3] + x.precip_depth_1_hr * model[4] + x.sea_level_pressure * model[5] + \n",
    "        x.is_holiday * model[6] + model[7])\n",
    "    x['meter_reading_lr_q'] = (meter_reading_log - meter_reading_lr)**2\n",
    "    return x\n",
    "\n",
    "df_test = df_test.apply(calculate_model, axis=1, result_type='expand')\n",
    "df_test_lr_rmsle = np.sqrt(df_test['meter_reading_lr_q'].sum() / len(df_test))\n",
    "print (f'Качество модели линейной регрессии: {round(df_test_lr_rmsle, 6)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 3\n",
    "##### Сравним предсказательную силу нескольких частных моделей линейной регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получите данные по энергопотреблению первых 20 зданий (building_id от 0 до 19).\n",
    "\n",
    "Заполните отсутствующие значения по погоде интерполяционными данными.\n",
    "\n",
    "Разделите данные на обучающие/проверочные в пропорции 80/20.\n",
    "\n",
    "Постройте (1) первый набор моделей линейной регрессии по часам для каждого из первых 20 зданий по следующим параметрам: air_temperature, dew_temperature, cloud_coverage, wind_speed, sea_level_pressure.\n",
    "\n",
    "Постройте для этих же 20 зданий (2) второй набор моделей линейной регрессии по часам по параметрам: дни недели и праздники (is_holiday). Требуется построить еще 480 моделей.\n",
    "\n",
    "Используйте логарифм целевого показателя (meter_reading_log) для обоих наборов моделей.\n",
    "\n",
    "Данные:\n",
    "\n",
    "https://video.ittensive.com/machine-learning/ashrae/building_metadata.csv.gz\n",
    "\n",
    "https://video.ittensive.com/machine-learning/ashrae/weather_train.csv.gz\n",
    "\n",
    "https://video.ittensive.com/machine-learning/ashrae/train.0.csv.gz\n",
    "\n",
    "Какая модель, 1 или 2, оказалась точнее для первого здания (building_id = 0) ?\n",
    "\n",
    "_______________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем данные в датафреймы и фильтруем по первым 20 зданиям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_buildings = pd.read_csv('http://video.ittensive.com/machine-learning/ashrae/building_metadata.csv.gz')\n",
    "df_weather = pd.read_csv('http://video.ittensive.com/machine-learning/ashrae/weather_train.csv.gz').set_index(['timestamp', 'site_id'])\n",
    "df_energy = pd.read_csv('http://video.ittensive.com/machine-learning/ashrae/train.0.csv.gz')\n",
    "df_energy = df_energy[df_energy['building_id'].isin(list(range(0, 20)))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соединяем датафреймы по индексам. Приводим дату к типу datetime, затем создаём колонку с часами. Создаём колонку поясняющую выходной день или нет. Фильтруем данные по показаниям счётчика, они должны быть больше нуля."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_energy.merge(df_buildings, how = 'left', on = 'building_id')\n",
    "df.set_index(['timestamp', 'site_id'], inplace = True)\n",
    "df = df.merge(df_weather, left_index = True, right_index = True, how = 'left')\n",
    "df.reset_index(inplace = True)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df['hours'] = df['timestamp'].apply(lambda x: x.hour)\n",
    "df = df.drop(columns=[\"meter\", \"site_id\", \"floor_count\"], axis=1)\n",
    "dates_range = pd.date_range(start = '2015-12-31', end = '2017-01-01')\n",
    "us_holidays = calendar().holidays(start = dates_range.min(), end = dates_range.max())\n",
    "df['is_holiday'] = (df['timestamp'].isin(us_holidays)).astype('int8')\n",
    "df = df[['timestamp', 'building_id', 'hours', 'air_temperature', 'dew_temperature', 'cloud_coverage', 'wind_speed',\n",
    "        'precip_depth_1_hr', 'sea_level_pressure', 'is_holiday', 'meter_reading']][df.meter_reading > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция уменьщения потребления памяти. Итерирует по колонкам, проверяет их тип и, если возможно, приводит их к типу, потребляющему меньше памяти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Потребление памяти меньше на 5.8 Мб (минус 62.9 %)\n"
     ]
    }
   ],
   "source": [
    "def reduce_mem_usage (df):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if str(col_type)[:5] == 'float':\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if c_min > np.finfo('f2').min and c_max < np.finfo('f2').max:\n",
    "                df[col] = df[col].astype(np.float16)\n",
    "            elif c_min > np.finfo('f4').min and c_max < np.finfo('f4').max:\n",
    "                df[col] = df[col].astype(np.float32)\n",
    "            else:\n",
    "                df[col] = df[col].astype(np.float64)\n",
    "        elif str(col_type)[:3] == 'int':\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if c_min > np.iinfo('i1').min and c_max < np.iinfo('i1').max:\n",
    "                df[col] = df[col].astype(np.int8)\n",
    "            elif c_min > np.iinfo('i2').min and c_max < np.iinfo('i2').max:\n",
    "                df[col] = df[col].astype(np.int16)\n",
    "            elif c_min > np.iinfo('i4').min and c_max < np.iinfo('i4').max:\n",
    "                df[col] = df[col].astype(np.int32)\n",
    "            elif c_min > np.iinfo('i8').min and c_max < np.iinfo('i8').max:\n",
    "                df[col] = df[col].astype(np.int64)\n",
    "        elif col == 'timestamp':\n",
    "            df[col] = pd.to_datetime(df[col])\n",
    "        elif str(col_type)[:8] != 'datetime':\n",
    "            df[col] = df[col].astype('category')\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(f'Потребление памяти меньше на {round(start_mem - end_mem, 2)} Мб (минус {round(100 * (start_mem - end_mem) / start_mem, 1)} %)')\n",
    "    return df\n",
    "\n",
    "df = reduce_mem_usage(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполняем пропуски интерполяцией данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "air_temperature Inf+NaN: 0\n",
      "dew_temperature Inf+NaN: 0\n",
      "cloud_coverage Inf+NaN: 0\n",
      "wind_speed Inf+NaN: 0\n",
      "precip_depth_1_hr Inf+NaN: 0\n",
      "sea_level_pressure Inf+NaN: 0\n"
     ]
    }
   ],
   "source": [
    "df['precip_depth_1_hr'] = df['precip_depth_1_hr'].apply(lambda x: x if x > 0 else 0)\n",
    "interpolate_columns = ['air_temperature', 'dew_temperature', 'cloud_coverage', \n",
    "                       'wind_speed', 'precip_depth_1_hr', 'sea_level_pressure']\n",
    "for col in interpolate_columns:\n",
    "    df[col] = df[col].interpolate(limit_direction='both', kind='cubic')\n",
    "    \n",
    "pd.set_option('use_inf_as_na', True)\n",
    "for col in interpolate_columns:\n",
    "    print(col, \"Inf+NaN:\", df[col].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обогащаем данные индексами дней."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>building_id</th>\n",
       "      <th>hours</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>cloud_coverage</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>precip_depth_1_hr</th>\n",
       "      <th>sea_level_pressure</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>meter_reading</th>\n",
       "      <th>day_0</th>\n",
       "      <th>day_1</th>\n",
       "      <th>day_2</th>\n",
       "      <th>day_3</th>\n",
       "      <th>day_4</th>\n",
       "      <th>day_5</th>\n",
       "      <th>day_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-02 09:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>18.296875</td>\n",
       "      <td>16.703125</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.099609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.228516</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-02 13:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>13.898438</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.101562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.218750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-04 13:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>8.898438</td>\n",
       "      <td>3.900391</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.101562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.023438</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04 17:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>15.601562</td>\n",
       "      <td>-0.600098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.101562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.682617</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-04 17:00:00</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>15.601562</td>\n",
       "      <td>-0.600098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.101562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>0</td>\n",
       "      <td>117.375000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp  building_id  hours  air_temperature  dew_temperature  \\\n",
       "0 2016-01-02 09:00:00            2      9        18.296875        16.703125   \n",
       "1 2016-01-02 13:00:00            1     13        15.000000        13.898438   \n",
       "2 2016-01-04 13:00:00            5     13         8.898438         3.900391   \n",
       "3 2016-01-04 17:00:00            5     17        15.601562        -0.600098   \n",
       "4 2016-01-04 17:00:00           11     17        15.601562        -0.600098   \n",
       "\n",
       "   cloud_coverage  wind_speed  precip_depth_1_hr  sea_level_pressure  \\\n",
       "0             4.0    3.099609                0.0              1018.0   \n",
       "1             4.0    4.101562                0.0              1020.0   \n",
       "2             4.0    4.101562                0.0              1016.0   \n",
       "3             0.0    4.101562                0.0              1017.0   \n",
       "4             0.0    4.101562                0.0              1017.0   \n",
       "\n",
       "   is_holiday  meter_reading  day_0  day_1  day_2  day_3  day_4  day_5  day_6  \n",
       "0           0       1.228516      0      0      1      0      0      0      0  \n",
       "1           0      35.218750      0      0      1      0      0      0      0  \n",
       "2           0       1.023438      0      0      0      0      1      0      0  \n",
       "3           0       0.682617      0      0      0      0      1      0      0  \n",
       "4           0     117.375000      0      0      0      0      1      0      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(inplace = True, drop = True)\n",
    "df['day'] = df['timestamp'].apply(lambda x: str(x.day) if x.day < 7 else str(x.day % 7)).astype('category')\n",
    "df = pd.get_dummies(df, columns = ['day'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём списки с названием колонок для двух датасетов: с погодными данными и днями недель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_data = df[['building_id', 'hours', 'air_temperature', 'dew_temperature', 'cloud_coverage', 'wind_speed', 'sea_level_pressure', 'meter_reading']]\n",
    "second_data = df[['building_id', 'hours', 'is_holiday', 'day_0', 'day_1','day_2','day_3','day_4','day_5','day_6', 'meter_reading']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделяем данные на обучающие и проверочные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_data_train, first_data_test = train_test_split(first_data, test_size = 0.2, random_state = 42)\n",
    "second_data_train, second_data_test = train_test_split(second_data, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для обучения. Итерирует по индексу зданий и часам. Для каждого здания создаёт почасовую модель потребления электричества. Заносит полученные коэффициенты в список. Возвращает список."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lr(df):\n",
    "    models = []\n",
    "    coeffs = []\n",
    "    for build_id in sorted(df['building_id'].unique()):\n",
    "        for hour in sorted(df.hours.unique()):\n",
    "            X = df[df['building_id'] == build_id].drop(columns = ['building_id', 'meter_reading'])\n",
    "            X = X[X['hours'] == hour].drop(columns = 'hours')\n",
    "            y = df[df['building_id'] == build_id]\n",
    "            y = y[y['hours'] == hour]['meter_reading']\n",
    "            model = LinearRegression()\n",
    "            model.fit(X, y)\n",
    "            coeffs.append(model.coef_)\n",
    "            coeffs[hour] = np.append(coeffs[hour], model.intercept_)\n",
    "        models.append(coeffs)\n",
    "        coeffs = []\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_1 = train_lr(first_data_train)\n",
    "models_2 = train_lr(second_data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем качество модели с погодными данными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\AI\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in log\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество модели линейной регрессии: 0.241957\n"
     ]
    }
   ],
   "source": [
    "def calculate_model_1(x):\n",
    "    model = models_1[int(x.building_id)][int(x.hours)]\n",
    "    meter_reading_log = np.log(x.meter_reading + 1)\n",
    "    meter_reading_lr = np.log(1 + x.air_temperature * model[0] + \n",
    "        x.dew_temperature * model[1] + x.cloud_coverage * model[2] +\n",
    "        x.wind_speed *  model[3] + x.sea_level_pressure * model[4] + model[5])\n",
    "    x['meter_reading_lr_q'] = (meter_reading_log - meter_reading_lr)**2\n",
    "    return x\n",
    "\n",
    "first_data_test = first_data_test.apply(calculate_model_1, axis = 1, result_type = 'expand')\n",
    "first_data_test_lr_rmsle = np.sqrt(first_data_test['meter_reading_lr_q'].sum() / len(first_data_test))\n",
    "print (f'Качество модели линейной регрессии: {round(first_data_test_lr_rmsle, 6)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем качество модели с днями недели и выходными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество модели линейной регрессии: 0.295338\n"
     ]
    }
   ],
   "source": [
    "def calculate_model_2(x):\n",
    "    model = models_2[int(x.building_id)][int(x.hours)]\n",
    "    meter_reading_log = np.log(x.meter_reading + 1)\n",
    "    meter_reading_lr = np.log(1 + x.is_holiday * model[0] + \n",
    "        x.day_0 * model[1] + x.day_1 * model[2] +\n",
    "        x.day_2 *  model[3] + x.day_3 * model[4] + \n",
    "        x.day_4 * model[5] + x.day_5 * model[6] + \n",
    "        x.day_6 * model[7] + model[8])\n",
    "    x['meter_reading_lr_q'] = (meter_reading_log - meter_reading_lr)**2\n",
    "    return x\n",
    "\n",
    "second_data_test = second_data_test.apply(calculate_model_2, axis = 1, result_type = 'expand')\n",
    "second_data_test_lr_rmsle = np.sqrt(second_data_test['meter_reading_lr_q'].sum() / len(second_data_test))\n",
    "print (f'Качество модели линейной регрессии: {round(second_data_test_lr_rmsle, 6)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравниваем качество моделей по индексам зданий, выясняем какая модель эффективнее для каждого из 20 зданий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Первая модель для зданий с индексом 0 предпочтительнее (0.22 < 0.26)\n",
      "Первая модель для зданий с индексом 1 предпочтительнее (0.3 < 0.38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\AI\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in log\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Первая модель для зданий с индексом 2 предпочтительнее (0.41 < 0.57)\n",
      "Первая модель для зданий с индексом 3 предпочтительнее (0.35 < 0.36)\n",
      "Первая модель для зданий с индексом 4 предпочтительнее (0.22 < 0.23)\n",
      "Первая модель для зданий с индексом 5 предпочтительнее (0.42 < 0.6)\n",
      "Первая модель для зданий с индексом 6 предпочтительнее (0.21 < 0.31)\n",
      "Первая модель для зданий с индексом 7 предпочтительнее (0.13 < 0.14)\n",
      "Первая модель для зданий с индексом 8 предпочтительнее (0.1 < 0.15)\n",
      "Первая модель для зданий с индексом 9 предпочтительнее (0.36 < 0.37)\n",
      "Первая модель для зданий с индексом 10 предпочтительнее (0.16 < 0.17)\n",
      "Первая модель для зданий с индексом 11 предпочтительнее (0.2 < 0.21)\n",
      "Первая модель для зданий с индексом 12 предпочтительнее (0.28 < 0.31)\n",
      "Первая модель для зданий с индексом 13 предпочтительнее (0.15 < 0.15)\n",
      "Первая модель для зданий с индексом 14 предпочтительнее (0.11 < 0.11)\n",
      "Первая модель для зданий с индексом 15 предпочтительнее (0.14 < 0.14)\n",
      "Первая модель для зданий с индексом 16 предпочтительнее (0.2 < 0.2)\n",
      "Первая модель для зданий с индексом 17 предпочтительнее (0.17 < 0.29)\n",
      "Первая модель для зданий с индексом 18 предпочтительнее (0.16 < 0.16)\n",
      "Первая модель для зданий с индексом 19 предпочтительнее (0.16 < 0.17)\n"
     ]
    }
   ],
   "source": [
    "for i in sorted(df['building_id'].unique()):\n",
    "    x1 = first_data_test[first_data_test['building_id'] == i].apply(calculate_model_1, axis = 1, result_type = 'expand')\n",
    "    x2 = second_data_test[second_data_test['building_id'] == i].apply(calculate_model_2, axis = 1, result_type = 'expand')\n",
    "    x1_rmsle = np.sqrt(x1['meter_reading_lr_q'].sum() / len(x1))\n",
    "    x2_rmsle = np.sqrt(x2['meter_reading_lr_q'].sum() / len(x2))\n",
    "    if x1_rmsle < x2_rmsle:\n",
    "        print(f'Первая модель для зданий с индексом {i} предпочтительнее ({round(x1_rmsle, 2)} < {round(x2_rmsle, 2)})')\n",
    "    else:\n",
    "        print(f'Вторая модель для зданий с индексом {i} предпочтительнее ({round(x1_rmsle, 2)} > {round(x2_rmsle, 2)})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 4\n",
    "##### Научимся экспортировать и импортировать промежуточные и конечные результаты, создавать ансамбли моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание задания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите данные и посчитайте модели линейной регрессии для 50 зданий по ансамблю регрессионных моделей: в первой модели весь оптимальный набор метеорологических данных, во второй - дни недели и праздники, в третьей - недели года, в четвертой - месяцы. Финальное значение показателя рассчитайте как взвешенное арифметическое показателей всех моделей, взяв веса для первой и второй модели как 3/8, а для третьей и четвертой - как 1/8.\n",
    "\n",
    "Загрузите данные решения, посчитайте значение энергопотребления для требуемых дат для тех зданий, которые посчитаны в модели, и выгрузите результат в виде CSV-файла (submission.csv).\n",
    "\n",
    "Данные:\n",
    "\n",
    "http://video.ittensive.com/machine-learning/ashrae/building_metadata.csv.gz\n",
    "\n",
    "http://video.ittensive.com/machine-learning/ashrae/weather_train.csv.gz\n",
    "\n",
    "http://video.ittensive.com/machine-learning/ashrae/train.0.csv.gz\n",
    "\n",
    "http://video.ittensive.com/machine-learning/ashrae/test.csv.gz\n",
    "\n",
    "http://video.ittensive.com/machine-learning/ashrae/weather_test.csv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings_metadata = pd.read_csv('http://video.ittensive.com/machine-learning/ashrae/building_metadata.csv.gz')\n",
    "weather_train = pd.read_csv('http://video.ittensive.com/machine-learning/ashrae/weather_train.csv.gz')\n",
    "train_0 = pd.read_csv('http://video.ittensive.com/machine-learning/ashrae/train.0.csv.gz')\n",
    "test = pd.read_csv('http://video.ittensive.com/machine-learning/ashrae/test.csv.gz')\n",
    "weather_test = pd.read_csv('http://video.ittensive.com/machine-learning/ashrae/weather_test.csv.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фильтруем данные по индексам первых 50 зданий. Объединяем обучающие данные по индексу. Приводим дату к типу datetime. Добавляем колонки с часами и выходными днями. Фильтруем датафрейм по показаниям счётчика, выбираем только нужные нам колонки. Логарифмируем показатель потребления энергии для уменьшения разброса данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train.set_index(['timestamp', 'site_id'], inplace = True)\n",
    "train_0 = train_0[train_0['building_id'].isin(list(range(0, 50)))]\n",
    "df = train_0.merge(buildings_metadata, how = 'left', on = 'building_id')\n",
    "df.set_index(['timestamp', 'site_id'], inplace = True)\n",
    "df = df.merge(weather_train, left_index = True, right_index = True, how = 'left')\n",
    "df.reset_index(inplace = True)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df['hours'] = df['timestamp'].apply(lambda x: x.hour)\n",
    "df = df.drop(columns=[\"meter\", \"site_id\", \"floor_count\"], axis=1)\n",
    "dates_range = pd.date_range(start = '2015-12-31', end = '2017-01-01')\n",
    "us_holidays = calendar().holidays(start = dates_range.min(), end = dates_range.max())\n",
    "df['is_holiday'] = (df['timestamp'].isin(us_holidays)).astype('int8')\n",
    "df = df[['timestamp', 'building_id', 'hours', 'air_temperature', 'dew_temperature', 'cloud_coverage', 'wind_speed',\n",
    "         'sea_level_pressure', 'is_holiday', 'meter_reading']][df.meter_reading > 0]\n",
    "df['meter_reading'] = df['meter_reading'].apply(lambda x: np.log(x) + 1) \n",
    "df.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция уменьщения потребления памяти. Итерирует по колонкам, проверяет их тип и, если возможно, приводит их к типу, потребляющему меньше памяти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Потребление памяти меньше на 12.83 Мб (минус 68.5 %)\n"
     ]
    }
   ],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if str(col_type)[:5] == 'float':\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if c_min > np.finfo('f2').min and c_max < np.finfo('f2').max:\n",
    "                df[col] = df[col].astype(np.float16)\n",
    "            elif c_min > np.finfo('f4').min and c_max < np.finfo('f4').max:\n",
    "                df[col] = df[col].astype(np.float32)\n",
    "            else:\n",
    "                df[col] = df[col].astype(np.float64)\n",
    "        elif str(col_type)[:3] == 'int':\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if c_min > np.iinfo('i1').min and c_max < np.iinfo('i1').max:\n",
    "                df[col] = df[col].astype(np.int8)\n",
    "            elif c_min > np.iinfo('i2').min and c_max < np.iinfo('i2').max:\n",
    "                df[col] = df[col].astype(np.int16)\n",
    "            elif c_min > np.iinfo('i4').min and c_max < np.iinfo('i4').max:\n",
    "                df[col] = df[col].astype(np.int32)\n",
    "            elif c_min > np.iinfo('i8').min and c_max < np.iinfo('i8').max:\n",
    "                df[col] = df[col].astype(np.int64)\n",
    "        elif col == 'timestamp':\n",
    "            df[col] = pd.to_datetime(df[col])\n",
    "        elif str(col_type)[:8] != 'datetime':\n",
    "            df[col] = df[col].astype('category')\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(f'Потребление памяти меньше на {round(start_mem - end_mem, 2)} Мб (минус {round(100 * (start_mem - end_mem) / start_mem, 1)} %)')\n",
    "    return df\n",
    "\n",
    "df = reduce_mem_usage(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполняем пропуски в данных с помощью интерполяции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "air_temperature Inf+NaN: 0\n",
      "dew_temperature Inf+NaN: 0\n",
      "cloud_coverage Inf+NaN: 0\n",
      "wind_speed Inf+NaN: 0\n",
      "sea_level_pressure Inf+NaN: 0\n"
     ]
    }
   ],
   "source": [
    "interpolate_columns = ['air_temperature', 'dew_temperature', 'cloud_coverage', \n",
    "                       'wind_speed', 'sea_level_pressure']\n",
    "for col in interpolate_columns:\n",
    "    df[col] = df[col].interpolate(limit_direction='both', kind='cubic')\n",
    "    \n",
    "pd.set_option('use_inf_as_na', True)\n",
    "for col in interpolate_columns:\n",
    "    print(col, \"Inf+NaN:\", df[col].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём списки с названиями колонок для создания датафреймов с погодными данными, индексами дней, недель и месяцев. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_features = df[['meter_reading', 'building_id', 'hours', 'air_temperature', 'dew_temperature', 'cloud_coverage',\n",
    "                       'wind_speed', 'sea_level_pressure']]\n",
    "days_features = df[['meter_reading', 'building_id', 'hours', 'timestamp', 'is_holiday']]\n",
    "week_features = df[['meter_reading', 'building_id', 'hours', 'timestamp']]\n",
    "month_features = df[['meter_reading', 'building_id', 'hours', 'timestamp']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём нужные нам датафреймы и обогащаем данные индексами дней, месяцев и недель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\AI\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "D:\\Anaconda\\envs\\AI\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "D:\\Anaconda\\envs\\AI\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "days_features['day'] = days_features['timestamp'].apply(lambda x: str(x.day) if x.day < 7 else str(x.day % 7)).astype('category')\n",
    "days_features = pd.get_dummies(days_features, columns = ['day'])\n",
    "week_features['week'] = week_features['timestamp'].apply(lambda x: str(x.week)).astype('category')\n",
    "week_features = pd.get_dummies(week_features, columns = ['week'])\n",
    "month_features['month'] = month_features['timestamp'].apply(lambda x: str(x.month)).astype('category')\n",
    "month_features = pd.get_dummies(month_features, columns = ['month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_features.drop('timestamp', axis = 1, inplace = True)\n",
    "week_features.drop('timestamp', axis = 1, inplace = True)\n",
    "month_features.drop('timestamp', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для обучения. Итерирует по индексу зданий и часам. Для каждого здания создаёт почасовую модель потребления электричества. Заносит полученные коэффициенты в список. Возвращает список."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lr(df):\n",
    "    models = []\n",
    "    coeffs = []\n",
    "    for build_id in sorted(df['building_id'].unique()):\n",
    "        for hour in sorted(df.hours.unique()):\n",
    "            X = df[df['building_id'] == build_id].drop(columns = ['building_id', 'meter_reading'])\n",
    "            X = X[X['hours'] == hour].drop(columns = 'hours')\n",
    "            y = df[df['building_id'] == build_id]\n",
    "            y = y[y['hours'] == hour]['meter_reading']\n",
    "            model = LinearRegression(fit_intercept = False)\n",
    "            model.fit(X, y)\n",
    "            coeffs.append(model.coef_)\n",
    "            coeffs[hour] = np.append(coeffs[hour], model.intercept_)\n",
    "        models.append(coeffs)\n",
    "        coeffs = []\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_model = train_lr(weather_features)\n",
    "days_model = train_lr(days_features)\n",
    "week_model = train_lr(week_features)\n",
    "month_model = train_lr(month_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполняем пропуски в тестовых данных. Фильтруем их по индексу зданий. Объединяем с данными по зданиям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in interpolate_columns:\n",
    "    weather_test[col] = weather_test[col].interpolate(limit_direction='both', kind='cubic')\n",
    "test = test[test.building_id < 50]\n",
    "test = test[test.meter == 0]\n",
    "test = pd.merge(left = test, right = buildings_metadata, how = 'left', left_on = 'building_id', right_on = 'building_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дропаем лишние колонки. Приводим дату к типу datetime, обогащаем данные индексами дней, недель, месяцев, выходных дней и часов. Объединяем все тестовые данные: с погодными данными и данными по дням, часам и т.д."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(['row_id', 'primary_use', 'square_feet', 'year_built', 'floor_count'], axis = 1, inplace = True)\n",
    "test.timestamp = pd.to_datetime(test.timestamp)\n",
    "weather_test.timestamp = pd.to_datetime(weather_test.timestamp)\n",
    "test['hours'] = test['timestamp'].apply(lambda x: x.hour)\n",
    "test['is_holiday'] = (test['timestamp'].isin(us_holidays)).astype('int8')\n",
    "test['day'] = test['timestamp'].apply(lambda x: str(x.day) if x.day < 7 else str(x.day % 7)).astype('category')\n",
    "test = pd.get_dummies(test, columns = ['day'])\n",
    "test['week'] = test['timestamp'].apply(lambda x: str(x.week)).astype('category')\n",
    "test = pd.get_dummies(test, columns = ['week'])\n",
    "test['month'] = test['timestamp'].apply(lambda x: str(x.month)).astype('category')\n",
    "test = pd.get_dummies(test, columns = ['month'])\n",
    "weather_test = weather_test.set_index(['timestamp', 'site_id'])\n",
    "test = test.set_index(['timestamp', 'site_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Потребление памяти меньше на 42.6 Мб (минус 36.6 %)\n"
     ]
    }
   ],
   "source": [
    "weather_test.drop(['precip_depth_1_hr', 'wind_direction'], axis = 1, inplace = True)\n",
    "test = pd.merge(left = test, right = weather_test, how = 'left', left_index = True, right_index = True)\n",
    "test = reduce_mem_usage(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для вычисления качества ансамбля моделей линейной регрессии. Веса для моделей взяты как 1/8 для моделей с месяцами и неделями и 3/8 для моделей с погодными данными и днями. Финальный показатель рассчитан как как взвешенное арифметическое показателей всех моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_test_data(df, weather_model, days_model, week_model, month_model):\n",
    "    for row, i in enumerate(df.iterrows()):\n",
    "        model_1 = weather_model[i[1][0]][i[1][2]]\n",
    "        model_2 = days_model[i[1][0]][i[1][2]]\n",
    "        model_3 = week_model[i[1][0]][i[1][2]]\n",
    "        model_4 = month_model[i[1][0]][i[1][2]]\n",
    "        total_lr = (3 / 8) * ((np.sum([c * v for c, v in zip(model_1[:-1], i[1][75:])])) \n",
    "                   + (np.sum([c * v for c, v in zip(model_2[:-1], i[1][3:11])]))) \n",
    "        + (1 / 8) * ((np.sum([c * v for c, v in zip(model_3[:-1], i[1][11:63])])) \n",
    "                   + (np.sum([c * v for c, v in zip(model_4[:-1], i[63:75])])))\n",
    "        df['meter'][row] = np.exp(total_lr)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассчитываем показатель потребления электричества для тестовых данных и заносим результаты в csv файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\AI\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "test.meter = test.meter.astype('float')\n",
    "result = calculate_test_data(test, weather_model, days_model, week_model, month_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result['meter']\n",
    "result.to_csv('submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
